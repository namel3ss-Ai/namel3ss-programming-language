# Content Analyzer Example

app "Content Analyzer" {
  description: "Analyze user-provided content for tone, topics, and risks."
}

llm "content_analyzer_llm" {
  provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.2
  max_tokens: 512

  # NOTE: parser/type-checker expect system_prompt, not system
  system_prompt: """
  You are a careful content analysis engine.

  - Identify main topics
  - Detect sentiment/tone
  - Flag any policy-violating, offensive, or risky content
  - Respond concisely and structured as JSON.
  """
}

prompt "analyze_content" {
  model: "content_analyzer_llm"

  template: """
  Analyze the following content.

  Content:
  {{content}}

  Return a JSON object with the following keys:
  - topics: string[]
  - sentiment: "positive" | "neutral" | "negative"
  - risk_level: "low" | "medium" | "high"
  - notes: string
  """
}

agent "ContentAnalyzerAgent" {
  llm: "content_analyzer_llm"

  # IMPORTANT:
  # - use memory policy name (string)
  # - NOT a named memory store like analysis_context
  # Valid policies: "conversation_window", "full_history", "summary", "none"
  memory: "conversation_window"
}