# Memory Chat Demo - demonstrates conversation memory, prompts, and chains

app "Memory Chat Demo" {
  description: "Stateful conversation sample highlighting memory primitives"
}

llm "gpt4" {
  provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 800
}

memory "conversation_history" {
  scope: "user"
  kind: "list"
  max_items: 100
}

memory "recent_topics" {
  scope: "session"
  kind: "list"
  max_items: 10
}

prompt "chat_response" {
  model: "gpt4"
  args: {
    user_message: string,
    fallback_name: string
  }
  template: """
You are a friendly AI assistant.
Previous messages:
{memory.conversation_history:6}

User ({fallback_name}): {user_message}
Assistant:
"""
  output_schema: {
    response: string,
    sentiment: string,
    topics: string
  }
}

chain "chat_flow" {
  description: "Loads preferences, generates response, and updates memories"

  step "respond" {
    kind: "prompt"
    target: "chat_response"
    options: {
      user_message: input.message
      fallback_name: "friend"
    }
  }

  step "topics" {
    kind: "memory_write"
    target: "recent_topics"
    options: {
      value: steps.respond.output.topics
    }
  }

  step "append_conversation" {
    kind: "memory_write"
    target: "conversation_history"
    options: {
      value: steps.respond.output.response
    }
  }
}

page "Chat" at "/chat" {
  show text "Memory Chat Demo"
  show text "Invoke chain chat_flow via CLI or runtime API"
}
