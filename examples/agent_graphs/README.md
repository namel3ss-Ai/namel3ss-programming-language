# Agent Graph Examples

Production-ready example workflows demonstrating the full Agent Graph Editor â†’ N3 Runtime pipeline.

## Examples

### 1. Customer Support Triage (`customer_support_triage.json`)

Intelligent ticket routing system with:
- **Classification**: Prompt-based ticket categorization with urgency detection
- **Conditional Routing**: Routes critical tickets to escalation agent, normal tickets to auto-response
- **RAG Integration**: Searches knowledge base for relevant documentation
- **Multi-Agent**: Escalation agent for urgent cases, auto-response agent for routine tickets
- **Summary Generation**: Consolidates all actions into dashboard-ready summary

**Use Case**: Automate first-line support triage, reduce response time by 60%, improve routing accuracy

**Components**:
- 2 Prompts (classify, summarize)
- 2 Agents (escalation, auto-response)
- 1 RAG Dataset (knowledge base)
- 1 Condition (urgency check)

**Estimated Cost**: ~$0.05 per execution

### 2. Research Pipeline (`research_pipeline.json`)

Multi-stage research workflow with:
- **Query Extraction**: Breaks down research questions into targeted search queries
- **RAG Search**: Hybrid search with reranking across research corpus
- **Research Agent**: Multi-turn agent that validates findings and identifies gaps
- **Synthesis**: Structured consolidation of findings with confidence scoring
- **Report Generation**: Professional report writer with citation formatting
- **Quality Check**: Automated quality assessment before publication

**Use Case**: Automate literature reviews, competitive analysis, market research

**Components**:
- 3 Prompts (extract queries, synthesize, quality check)
- 2 Agents (researcher, writer)
- 1 RAG Dataset (research corpus)

**Estimated Cost**: ~$0.25 per execution

## Execution

### Prerequisites

```bash
# Set OpenAI API key
export OPENAI_API_KEY="your-api-key-here"

# Install dependencies
pip install -r requirements.txt
```

### Run Examples

```bash
# Execute customer support triage
python examples/agent_graphs/execute_example.py --graph customer_support_triage

# Execute research pipeline with verbose logging
python examples/agent_graphs/execute_example.py --graph research_pipeline --verbose
```

### Example Output

```
2024-11-21 10:30:15 - __main__ - INFO - Loading graph: customer_support_triage
2024-11-21 10:30:15 - __main__ - INFO - Converting graph to N3 AST...
2024-11-21 10:30:15 - __main__ - INFO - Conversion summary: {'agents': 2, 'prompts': 2, 'rag_pipelines': 1, 'total_nodes': 5}
2024-11-21 10:30:16 - __main__ - INFO - Executing chain with input: {'ticket_text': '...', 'customer_tier': 'enterprise'}
2024-11-21 10:30:28 - __main__ - INFO - ================================================================================
2024-11-21 10:30:28 - __main__ - INFO - EXECUTION COMPLETE
2024-11-21 10:30:28 - __main__ - INFO - ================================================================================
2024-11-21 10:30:28 - __main__ - INFO - Output: {
  "summary": "Critical login issue escalated to on-call team",
  "next_steps": ["Verify email delivery", "Check account status", "Manual password reset"],
  "assigned_team": "Platform Engineering"
}
2024-11-21 10:30:28 - __main__ - INFO - Total tokens: 1247
2024-11-21 10:30:28 - __main__ - INFO - Total cost: $0.0312
2024-11-21 10:30:28 - __main__ - INFO - 
âœ… Execution successful!
```

## Graph Structure

Both examples follow the validated structure:

```typescript
{
  "projectId": string,
  "name": string,
  "description": string,
  "nodes": [
    {
      "id": string,
      "type": "start" | "end" | "prompt" | "agent" | "ragDataset" | "condition",
      "label": string,
      "position": {x: number, y: number},
      "data": {...}  // Type-specific node data
    }
  ],
  "edges": [
    {
      "id": string,
      "source": string,  // Node ID
      "target": string,  // Node ID
      "label"?: string   // Optional condition label
    }
  ],
  "metadata": {...}
}
```

## Integration with Database

To persist graphs to the database:

```python
from n3_server.database.models import Project, AgentGraph
from sqlalchemy.orm import Session

# Create project
project = Project(
    name="Customer Support System",
    description="Automated support triage"
)
session.add(project)
session.flush()

# Create graph
with open("customer_support_triage.json") as f:
    graph_data = json.load(f)

agent_graph = AgentGraph(
    project_id=project.id,
    name=graph_data["name"],
    description=graph_data["description"],
    graph_json=graph_data,
    version=1
)
session.add(agent_graph)
session.commit()

# Execute via API
response = requests.post(
    f"http://localhost:8000/api/execution/graphs/{agent_graph.id}/execute",
    json={"input_data": {...}}
)
```

## Next Steps

1. **Add Custom Tools**: Extend agents with domain-specific tool implementations
2. **RAG Data Ingestion**: Populate RAG datasets with your documents
3. **Frontend Integration**: Connect these examples to the visual graph editor
4. **Production Deployment**: Add authentication, rate limiting, monitoring
5. **Cost Optimization**: Tune model selection, prompt sizes, agent turn limits

## Testing

The examples are validated by:
- âœ… Pydantic v2 schema validation (17 tests)
- âœ… AST conversion correctness (17 tests)  
- âœ… Runtime execution with mocks (12 tests)
- ðŸ”„ E2E execution with real LLMs (manual testing)

Total test coverage: **29/29 passing**
