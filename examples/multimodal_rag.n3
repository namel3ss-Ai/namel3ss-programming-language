app "Multimodal Product Documentation Assistant" {
  description: "Multimodal RAG demo"
}

// LLM for generating answers
llm "gpt4" {
    provider: "openai"
    model: "gpt-4"
    temperature: 0.7
}

// Dataset of product documentation (PDFs with images)
dataset "product_docs" {
    source: "data/product_docs/"
    format: "directory"
    recursive: true
}

// Multimodal index with image extraction
index "docs_index" {
    source_dataset: "product_docs"
    embedding_model: "all-MiniLM-L6-v2"
    chunk_size: 512
    overlap: 64
    backend: "qdrant"
    collection: "product_docs_multimodal"
    
    // Extract images from PDFs
    extract_images: true
    image_model: "openai/clip-vit-base-patch32"
    
    // Extract audio from videos (if any)
    extract_audio: false
    audio_model: "openai/whisper-base"
}

// Hybrid RAG pipeline with advanced retrieval
rag_pipeline "multimodal_retrieval" {
    query_encoder: "all-MiniLM-L6-v2"
    index: "docs_index"
    top_k: 20  // Retrieve 20 candidates
    
    // Hybrid search: combine dense vector + sparse BM25
    enable_hybrid: true
    sparse_model: "bm25"
    dense_weight: 0.7
    sparse_weight: 0.3
    
    // Rerank top candidates
    reranker: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    reranker_type: "cross_encoder"
    distance_metric: "cosine"
}

// Prompt template for question answering
prompt "qa_prompt" {
    input: [
        - name: "question"
          type: text
          required: true
        - name: "contexts"
          type: text
          required: true
    ]
    
    template: """
        You are a helpful product documentation assistant.
        
        Answer the following question based ONLY on the provided contexts.
        If the answer is not in the contexts, say "I don't have enough information."
        
        Contexts:
        {contexts}
        
        Question: {question}
        
        Answer:
    """
    
    output: [
        - name: "answer"
          type: text
    ]
}

// Chain combining RAG + LLM
chain "qa_chain" {
    steps: ["input", "rag:multimodal_retrieval", "prompt:qa_prompt", "llm:gpt4"]
}

// Memory for conversation history
memory "conversation_memory" {
    type: "buffer"
    max_messages: 10
}

// Agent with tools
tool "search_docs" {
    description: "Search product documentation"
    implementation: "chain:qa_chain"
}

agent "support_agent" {
    llm: "gpt4"
    tools: ["search_docs"]
    memory: "conversation_memory"
    instructions: """
        You are a product support agent. Use the search_docs tool to find 
        relevant information from documentation when answering user questions.
    """
}

// Web interface
page "Ask Documentation" at "/ask" {
    show form {
        fields: "question"
        on_submit: "run:qa_chain"
    }
    show response {
        source: "chain.answer"
    }
}

page "Chat with Agent" at "/chat" {
    show chat {
        agent: "support_agent"
        title: "Product Support Assistant"
    }
}
