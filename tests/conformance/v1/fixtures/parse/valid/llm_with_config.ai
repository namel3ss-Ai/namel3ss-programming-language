llm "gpt4" {
    provider: "openai"
    model: "gpt-4"
    temperature: 0.7
    max_tokens: 2000
}